{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiQ5eDr0PqJk",
        "outputId": "45347eab-c273-44be-b124-b90d2391646c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current working directory: c:\\Users\\ssnay\\Documents\\GitHub\\Hack-MITWPU-Syntax_Terror-sepsis_Detection\n",
            "Files in directory: ['.git', '.gitignore', 'Best__1_21.ipynb', 'Content', 'LICENSE', 'README.md', 'submission.csv']\n",
            "Files loaded successfully!\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "[LightGBM] [Info] Number of positive: 40078, number of negative: 39922\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000736 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2295\n",
            "[LightGBM] [Info] Number of data points in the train set: 80000, number of used features: 9\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500975 -> initscore=0.003900\n",
            "[LightGBM] [Info] Start training from score 0.003900\n",
            "Best parameters: {'lgbm__learning_rate': 0.1, 'lgbm__max_depth': -1, 'lgbm__n_estimators': 200, 'lgbm__num_leaves': 50}\n",
            "Best cross-validation F1 score: 0.9947\n",
            "F1 Score on validation set: 0.9953\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ssnay\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Number of positive: 50000, number of negative: 50000\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018512 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 2295\n",
            "[LightGBM] [Info] Number of data points in the train set: 100000, number of used features: 9\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
            "Submission file 'submission.csv' created successfully!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ssnay\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Print current working directory and list files\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "print(f\"Files in directory: {os.listdir()}\")\n",
        "\n",
        "# Load the datasets\n",
        "try:\n",
        "    train_data = pd.read_csv(\"Content/Train_Data.csv\")\n",
        "    test_data = pd.read_csv(\"Content/Test_Data.csv\")\n",
        "    print(\"Files loaded successfully!\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    # You might want to stop execution here or provide alternative paths\n",
        "    raise\n",
        "\n",
        "# Separate features and target\n",
        "X = train_data.drop(columns=[\"Sepssis\"])\n",
        "y = train_data[\"Sepssis\"]  # 'Negative' or 'Positive'\n",
        "\n",
        "# Convert target to binary (LightGBM needs numeric labels for training)\n",
        "y = y.map({'Negative': 0, 'Positive': 1})\n",
        "\n",
        "# Split for validation\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Identify numerical and categorical columns\n",
        "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Preprocessing for numerical data\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "# Preprocessing for categorical data (LightGBM handles categories natively, but we impute missing)\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\"))\n",
        "])\n",
        "\n",
        "# Combine preprocessing steps\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", numeric_transformer, numeric_cols),\n",
        "        (\"cat\", categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Full pipeline with preprocessing and LightGBM\n",
        "pipeline = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"lgbm\", LGBMClassifier(random_state=42, objective=\"binary\"))\n",
        "])\n",
        "\n",
        "# Define parameter grid for tuning\n",
        "param_grid = {\n",
        "    \"lgbm__n_estimators\": [100, 200],\n",
        "    \"lgbm__learning_rate\": [0.01, 0.1],\n",
        "    \"lgbm__max_depth\": [3, 5, -1],  # -1 means no limit\n",
        "    \"lgbm__num_leaves\": [31, 50]\n",
        "}\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring=\"f1\", n_jobs=-1, verbose=1)\n",
        "grid_search.fit(X_train, y_train, lgbm__categorical_feature=categorical_cols.tolist())\n",
        "\n",
        "# Best model\n",
        "best_model = grid_search.best_estimator_\n",
        "print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best cross-validation F1 score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Evaluate on validation set\n",
        "y_val_pred = best_model.predict(X_val)\n",
        "f1 = f1_score(y_val, y_val_pred)\n",
        "print(f\"F1 Score on validation set: {f1:.4f}\")\n",
        "\n",
        "# Train on full dataset\n",
        "best_model.fit(X, y, lgbm__categorical_feature=categorical_cols.tolist())\n",
        "\n",
        "# Predict on test set\n",
        "test_predictions = best_model.predict(test_data)\n",
        "\n",
        "# Convert predictions back to 'Negative'/'Positive' for submission\n",
        "test_predictions = np.where(test_predictions == 0, 'Negative', 'Positive')\n",
        "\n",
        "# Prepare submission\n",
        "submission_df = pd.DataFrame({\"Sepssis\": test_predictions})\n",
        "submission_df.to_csv(\"submission.csv\", index=False)\n",
        "\n",
        "print(\"Submission file 'submission.csv' created successfully!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
